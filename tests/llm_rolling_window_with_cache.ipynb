{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-18T06:26:04.792213Z",
     "start_time": "2025-08-18T06:26:04.126221Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Strategy:\n",
    "# Extract pos_ner + embeddings & rolling embeddings\n",
    "# Flag bad ner, use POS to get the numbers and potential other bad stuff\n",
    "# Project embeddings & rolling embeddings, cosine sim with all other clusters ?\n",
    "# Then rules for numbers\n",
    "\n",
    "text_path = '../example_conversations/english/labelled_text_conv_1.json'\n",
    "\n",
    "with open(text_path, 'r') as f:\n",
    "    labelled_data = json.load(f)\n",
    "\n",
    "unlabelled_data = [list(i.keys())[0] for i in labelled_data]\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:26:07.282189Z",
     "start_time": "2025-08-18T06:26:06.264748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import notebook_login, login\n",
    "\n",
    "with open('hf_token.txt', 'r') as f:\n",
    "    token = f.read()\n",
    "\n",
    "login(token)"
   ],
   "id": "fcc5ba6d185ca490",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:29:22.440601Z",
     "start_time": "2025-08-18T06:26:20.629558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "SMALL_MODEL = False\n",
    "\n",
    "if SMALL_MODEL:\n",
    "    MODEL_ID = 'google/gemma-3-1b-it'\n",
    "else:\n",
    "    MODEL_ID = 'google/gemma-3-12b-it'\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, device_map={'': 'cpu'}, torch_dtype=dtype)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.config.use_cache = True\n",
    "device = model.device\n",
    "print(device)"
   ],
   "id": "7341faf8ae82443e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a6de21bbac84fc7b76ecc8dba0a7480"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:34:01.032479Z",
     "start_time": "2025-08-18T06:34:01.025350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../prompt2.txt', 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "rolled_window_data = []\n",
    "win_down, win_up = -5, 5\n",
    "for idx, word in enumerate(unlabelled_data):\n",
    "    start, end = idx + win_down, idx + win_up\n",
    "    start = max(0, start)\n",
    "    end = min(end, len(unlabelled_data))\n",
    "\n",
    "    rolled_window_data.append((' '.join(unlabelled_data[start:end]), word, idx))\n",
    "\n",
    "def make_suffix(sentence: str, word_: str) -> str:\n",
    "    return f'Sentence: {sentence}\\nWord: {word_}\\nAnswer:'"
   ],
   "id": "dcc4fea7c5a17550",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T13:43:40.383940Z",
     "start_time": "2025-08-15T13:43:24.444517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get KV cache\n",
    "with torch.inference_mode():\n",
    "    pref_inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    pref_out = model(**pref_inputs, use_cache=True)\n",
    "    prompt_kv = pref_out.past_key_values\n",
    "    past_len = pref_inputs.input_ids.size(1)"
   ],
   "id": "5758fcb25b7b1e30",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T13:43:43.464337Z",
     "start_time": "2025-08-15T13:43:43.453677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def continue_from_cache(prefix_kv, suffix, max_new_tokens=2, greedy=True):\n",
    "\n",
    "    def forward_pass(input_ids, kv):\n",
    "        past_len = kv[0][0].shape[-2]\n",
    "        pos_ids = torch.arange(past_len, past_len + input_ids.size(1), device=device).unsqueeze(0)\n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=torch.ones_like(input_ids),\n",
    "                    position_ids=pos_ids,\n",
    "                    past_key_values=kv,\n",
    "                    use_cache=True)\n",
    "        return out\n",
    "\n",
    "    def get_next_token(logits):\n",
    "        if greedy:\n",
    "            return logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "\n",
    "        return torch.distributions.Categorical(logits=logits[:, -1, :]).sample().unsqueeze(0)\n",
    "\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        suf = tokenizer(suffix, return_tensors='pt').to(device)\n",
    "\n",
    "        out = forward_pass(suf.input_ids, prefix_kv)\n",
    "\n",
    "        next_token = get_next_token(out.logits)\n",
    "\n",
    "        kv = out.past_key_values\n",
    "        generated = [next_token]\n",
    "\n",
    "        for _ in range(max_new_tokens - 1):\n",
    "\n",
    "            out = forward_pass(next_token, kv)\n",
    "\n",
    "            next_token = get_next_token(out.logits)\n",
    "\n",
    "            generated.append(next_token)\n",
    "            kv = out.past_key_values\n",
    "\n",
    "    return tokenizer.decode(torch.cat(generated, dim=1)[0], skip_special_tokens=True)"
   ],
   "id": "29cbdcb326afeaa8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T13:43:49.713071Z",
     "start_time": "2025-08-15T13:43:45.191007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "suffix_ = make_suffix(rolled_window_data[0][0], rolled_window_data[0][1])\n",
    "\n",
    "output = continue_from_cache(prefix_kv=prompt_kv, suffix=suffix_, max_new_tokens=5)"
   ],
   "id": "c694274e1a7f7353",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T13:43:50.653765Z",
     "start_time": "2025-08-15T13:43:50.647801Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "7929bc9866af23de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', and///'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:36:14.338058Z",
     "start_time": "2025-08-18T06:35:38.662359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt')\n",
    "out = model(**tokens)\n",
    "tokenizer.decode(out.logits)"
   ],
   "id": "311346cfc5640254",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(out.logits)",
   "id": "c808da5a117e8afc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "15cad24352c3fbbd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
